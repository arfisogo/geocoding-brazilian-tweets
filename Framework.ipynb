{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"gEy5exCRfNQv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672005419130,"user_tz":180,"elapsed":38701,"user":{"displayName":"Arthur Filipe Sousa Gomes","userId":"14928857500750418910"}},"outputId":"11d4cbdc-b57e-4187-96d8-9156f3326ce2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["\n","#Montando local para alimentacão das bases do twitter e de cidades brasileiras\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Ey4vfgnUDt1x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672005447319,"user_tz":180,"elapsed":19455,"user":{"displayName":"Arthur Filipe Sousa Gomes","userId":"14928857500750418910"}},"outputId":"01ceec88-1874-4ffc-b11e-6ad2dfe692d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rapidfuzz\n","  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 23.2 MB/s \n","\u001b[?25hInstalling collected packages: rapidfuzz\n","Successfully installed rapidfuzz-2.13.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jsonmerge\n","  Downloading jsonmerge-1.9.0.tar.gz (32 kB)\n","Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonmerge) (4.3.3)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>2.4.0->jsonmerge) (5.10.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>2.4.0->jsonmerge) (22.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>2.4.0->jsonmerge) (0.19.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>2.4.0->jsonmerge) (3.11.0)\n","Building wheels for collected packages: jsonmerge\n","  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonmerge: filename=jsonmerge-1.9.0-py3-none-any.whl size=18633 sha256=4e9419335310f7b2bf815d71df02c6196764291eb1de822e3f44457cb954e75b\n","  Stored in directory: /root/.cache/pip/wheels/82/c3/9a/421a7eabc04d18b19ee10e43646bea935e518eb88a6e5e9df7\n","Successfully built jsonmerge\n","Installing collected packages: jsonmerge\n","Successfully installed jsonmerge-1.9.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xlrd in /usr/local/lib/python3.8/dist-packages (1.2.0)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]}],"source":["#Instalação e importação das bibliotecas necessarias\n","!pip install nltk\n","!pip install fuzzywuzzy\n","!pip install rapidfuzz\n","!pip install jsonmerge\n","!pip install xlrd\n","import pandas as pd\n","import difflib as dif\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","import os\n","import re\n","from jsonmerge import merge\n","from pandas.io.json import json_normalize\n","from fuzzywuzzy import fuzz\n","from fuzzywuzzy import process\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, WordPunctTokenizer\n","ambiguas = ['Água Boa','Brasil','brasil','br','Água Branca', 'Alagoinha', 'Alto Alegre', 'Alto Paraíso', 'Alvorada', 'Amparo', 'Anchieta', 'Antônio Carlos', 'Aparecida', 'Araguanã', 'Araruna', 'Areia Branca', 'Atalaia', 'Aurora', 'Bandeirantes', 'Baraúna', 'Barra Bonita', 'Barracão', 'Barro Alto', 'Batalha', 'Belém', 'Belmonte', 'Boa Esperança', 'Boa Vista', 'Bocaina', 'Bom Jardim', 'Bom Jesus', 'Bom Jesus do Tocantins', 'Bom Sucesso', 'Bonfim', 'Bonito', 'Borborema', 'Brejinho', 'Buritis', 'Cachoeira Dourada', 'Cachoeirinha', 'Cafelândia', 'Caiçara', 'Campestre', 'Campo Alegre', 'Campo Grande', 'Canápolis', 'Canarana', 'Candeias', 'Cantagalo', 'Capanema', 'Capela', 'Caracol', 'Caraúbas', 'Cascavel', 'Catanduvas', 'Cedral', 'Cedro', 'Centenário', 'Colinas', 'Colorado', 'Condado', 'Conde', 'Cruzeiro do Sul', 'Davinopólis', 'Douradinha', 'Eldorado', 'Entre Rios', 'Esperantina', 'Estrela do Norte', 'Fátima', 'Feira Nova', 'Filadélfia', 'Floresta', 'Formoso', 'General Carneiro', 'Gravataí', 'Guaíra', 'Guaraci', 'Guaraciaba', 'Hidrolândia', 'Humaitá', 'Iguatu', 'Inajá', 'Independência', 'Indianápolis', 'Ipueiras', 'Iracema', 'Irati', 'Itabaiana', 'Itajá', 'Itambé', 'Itapeva', 'Itapiranga', 'Itaporanga', 'Jaborandi', 'Jacutinga', 'Jandaíra', 'Japurá', 'Jardim', 'Jardinópolis', 'Jatobá', 'Jundiá', 'Jurema', 'Jussara', 'Lagoa Grande', 'Lagoa Santa', 'Lajeado', 'Laranjal', 'Maravilha', 'Massaranduba', 'Mesquita', 'Milagres', 'Mirador', 'Monte Alegre', 'Monte Castelo', 'Morrinhos', 'Mulungu', 'Mundo Novo', 'Natividade', 'Nazaré', 'Nova Aurora', 'Nova Fátima', 'Nova Olímpia', 'Nova Olinda', 'Nova Santa Rita', 'Nova União', 'Nova Veneza', 'Novo Horizonte', 'Novo Santo Antônio', 'Ouro Branco', 'Ouro Verde', 'Pacatuba', 'Palestina', 'Palmas', 'Palmeira', 'Palmital', 'Paraíso', 'Parnamirim', 'Passagem', 'Pau D’Arco', 'Paulista', 'Pedra Branca', 'Pedra Preta', 'Petrolândia', 'Pilar', 'Pilões', 'Pinhalzinho', 'Pinhão', 'Pitangueiras', 'Planaltina', 'Planalto', 'Praia Grande', 'Prata', 'Presidente Bernardes', 'Presidente Dutra', 'Presidente Juscelino', 'Presidente Kennedy', 'Presidente Médici', 'Primavera', 'Queimadas', 'Redenção', 'Riachão', 'Riachinho', 'Riacho de Santana', 'Riachuelo', 'Rio Branco', 'Rio Claro', 'Rio Negro', 'Rio Verde', 'Ruy Barbosa', 'Salgadinho', 'Saltinho', 'Santa Bárbara', 'Santa Cecília', 'Santa Cruz', 'Santa Filomena', 'Santa Helena', 'Santa Inês', 'Santa Isabel', 'Santa Lúcia', 'Santa Luzia', 'Santa Maria', 'Santa Rita', 'Santa Rosa de Lima', 'Santa Teresinha', 'Santa Terezinha', 'Santana', 'Santarém', 'Santo André', 'São Bento', 'São Carlos', 'São Domingos', 'São Francisco', 'São Francisco de Paula', 'São Gabriel', 'São Gonçalo do Amarante', 'São João', 'São João Batista', 'São João do Paraíso', 'São José do Divino', 'São Martinho', 'São Pedro', 'São Sebastião', 'São Simão', 'São Tomé', 'São Vicente', 'São Vicente Ferrer', 'Sapucaia', 'Sarandi', 'Serrinha', 'Sertãozinho', 'Sítio Novo', 'Sobradinho', 'Soledade', 'Tabatinga', 'Tangará', 'Tapejara', 'Tapira', 'Tapiraí', 'Tavares', 'Teodoro Sampaio', 'Terra Nova', 'Terra Roxa', 'Toledo', 'Trindade', 'Triunfo', 'Turmalina', 'Turvo', 'Valença', 'Vargem', 'Vargem Bonita', 'Várzea', 'Várzea Grande', 'Vera Cruz', 'Viana', 'Viçosa', 'Wenceslau Braz', 'São Paulo', 'Rio de Janeiro','são paulo']\n","ambiguas.sort()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8oDCFHFlFOYT","executionInfo":{"status":"ok","timestamp":1672005466075,"user_tz":180,"elapsed":1654,"user":{"displayName":"Arthur Filipe Sousa Gomes","userId":"14928857500750418910"}}},"outputs":[],"source":["#Abertura da base de tuítes, normalização dos niveis\n","with open('/content/drive/MyDrive/TCC/SRC/dataset_2021-04-27.json') as json_file:  \n","    d = json.load(json_file)\n","    rec = d\n","    dataset = pd.json_normalize(rec['tweets'], max_level=6)\n","dataset.to_csv('sample.csv')"]},{"cell_type":"code","source":["import glob\n","\n","json_dir = '/content/drive/MyDrive/TCC/SRC'\n","\n","json_pattern = os.path.join(json_dir, '*.json')\n","file_list = glob.glob(json_pattern)\n","\n","dfs = []\n","for file in file_list:\n","    with open(file) as f:\n","        json_data = pd.json_normalize(json.loads(f.read())['tweets'],max_level=6)\n","        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n","    dfs.append(json_data)\n","df = pd.concat(dfs)"],"metadata":{"id":"DGC01kDPbaO5","executionInfo":{"status":"ok","timestamp":1672005475465,"user_tz":180,"elapsed":4351,"user":{"displayName":"Arthur Filipe Sousa Gomes","userId":"14928857500750418910"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(df.head(1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jL6cQY3vSvpb","executionInfo":{"status":"ok","timestamp":1672005773422,"user_tz":180,"elapsed":267,"user":{"displayName":"Arthur Filipe Sousa Gomes","userId":"14928857500750418910"}},"outputId":"62ca1c40-2d88-43f4-ac0b-a28dc7bcedb1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["                       created_at                   id               id_str  \\\n","0  Wed Apr 28 23:59:31 +0000 2021  1387557117951975428  1387557117951975428   \n","\n","                                           full_text  truncated  \\\n","0  Atualização dos dados do Brasil. #coronavirus ...      False   \n","\n","  display_text_range                                             source  \\\n","0            [0, 54]  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n","\n","   in_reply_to_status_id in_reply_to_status_id_str  in_reply_to_user_id  ...  \\\n","0                    NaN                      None                  NaN  ...   \n","\n","  quoted_status.place.name quoted_status.place.full_name  \\\n","0                      NaN                           NaN   \n","\n","   quoted_status.place.country_code  quoted_status.place.country  \\\n","0                               NaN                          NaN   \n","\n","   quoted_status.place.contained_within quoted_status.place.bounding_box.type  \\\n","0                                   NaN                                   NaN   \n","\n","   quoted_status.place.bounding_box.coordinates  \\\n","0                                           NaN   \n","\n","   quoted_status.quoted_status_id  quoted_status.quoted_status_id_str  \\\n","0                             NaN                                 NaN   \n","\n","                      site  \n","0  dataset_2021-04-28.json  \n","\n","[1 rows x 179 columns]\n"]}]},{"cell_type":"code","source":["#Atribuição a um data frame - uma base\n","df = pd.concat([df['id'],df['user.location']],axis=1,keys=['id', 'localizacao'])\n","df.astype({\"localizacao\": str})\n","df = df.convert_dtypes()\n","df.dtypes"],"metadata":{"id":"yNjriXiyb-do"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df = re.sub('\\W+',' ',))"],"metadata":{"id":"DDh4-akjKhrs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Atribuição a um data frame - uma base\n","#df = pd.concat([dataset['id'],dataset['user.location']],axis=1,keys=['id', 'localizacao'])"],"metadata":{"id":"jcaJThogd2QJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUjdFwiRgwtW"},"outputs":[],"source":["base_municipios = pd.read_excel(r'/content/drive/MyDrive/TCC/SRC/RELATORIO_DTB_BRASIL_MUNICIPIO.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQed2vL0iP8c"},"outputs":[],"source":["#União das bases de municípios e estados brasileiros\n","in_first = set(list(base_municipios.Nome_Município))\n","in_second = set(list(base_municipios.Nome_UF))\n","in_second_but_not_in_first = in_second - in_first\n","result = list(base_municipios.Nome_Município) + list(in_second_but_not_in_first)\n","for i in range(len(result)):\n","\n","    result[i] = result[i].lower()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTKppyHLwAZS"},"outputs":[],"source":["dic = df.set_index('id').T.to_dict('records')\n","print(dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZlCU8Wd9SW9r"},"outputs":[],"source":["tweet_tokenizer = TweetTokenizer()\n","wpt = WordPunctTokenizer()\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","portuguesestopwords = set(stopwords.words('portuguese'))\n","#portuguesestopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfSfi06W3QU7"},"outputs":[],"source":["def fillVmatch(x):\n","    word_to_check = x\n","    if not word_to_check:\n","        return 0\n","    a = process.extract(word_to_check,result,limit=1)\n","    if a[0][1]>= 90 and a[0][1]<= 100:\n","      # print('----FILLVMATCH----' + x + ' ' + str(a[0][1]))\n","         return a[0][1]\n","    else:\n","         return 0\n","def fillVName(c):\n","    word_to_check = c\n","    if not word_to_check:\n","      return 0\n","    a = process.extract(word_to_check,result, limit=1)\n","    if a[0][1]>= 90 and a[0][1]<= 100:\n","      # print('----FILLVNAME----' + c + ' ' + str(a[0][0]))\n","      return a[0][0]\n","    else:\n","        return ''"]},{"cell_type":"code","source":["def lower_dict(d):\n","   new_dict = dict((k, v.lower()) for k, v in d.items())\n","   return new_dict"],"metadata":{"id":"cnBgY3ATAhSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(dic)):\n","    dic[i] = lower_dict(dic[i])\n","str_list = list(filter(None, dic))\n","print(str_list)\n"],"metadata":{"id":"Xmreq_9W_bqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQsfukrOxfnT"},"outputs":[],"source":["# print(dic[0])\n","dicionario = dic[0]\n","dicionario2 = {}\n","for i in dicionario:\n","    #dicionario[i] = word_tokenize(dicionario[i])\n","    #dicionario[i] = [x for x in dicionario[i] if x not in portuguesestopwords]\n","    listaTemp = []\n","    #print(dicionario[i])\n","   # for value in dicionario[i]:\n","       #print(teste)\n","    sublista = []\n","\n","    sublista.append(dicionario[i])\n","    sublista.append(fillVmatch(dicionario[i]))\n","    sublista.append(fillVName(dicionario[i]))\n","\n","    listaTemp.append(sublista)\n","\n","    dicionario2[i] = listaTemp\n","    print(dicionario2)\n","    # tokens_without_stopwords = [x for x in tokens if x not in portuguesestopwords]   \n","    # print(tokens_without_stopwords)\n","    # print(fillVmatch(str(tokens_without_stopwords)))\n","    # print(fillVName(str(tokens_without_stopwords)))\n","    #a.append(tokens_without_stopwords)\n","print(dicionario2)\n","#fdist = nltk.FreqDist(p.lower() for p in a)\n"]},{"cell_type":"code","source":["dic[0]"],"metadata":{"id":"8yler7-jegzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dicionario = dic[0]\n","dicionario2 = {}\n","index = 0\n","limit = 15\n","df2 = pd.DataFrame(columns=('ID', '%Similaridade', 'Local_Sugerido','Ambiguidade'))\n","for i in dicionario:\n","   index += 1\n","   if index == limit:\n","        break\n","   res = str(fillVName(re.sub('\\W+',' ', dicionario[i])))\n","   if not dif.get_close_matches(res, ambiguas, n=1, cutoff=0.8):\n","    df2.loc[i] = [str(re.sub('\\W+',' ', dicionario[i])), str(fillVmatch(dicionario[i])), res,'N']\n","   else:\n","    df2.loc[i] = [str(re.sub('\\W+',' ', dicionario[i])), str(fillVmatch(dicionario[i])), res,'S']\n","index = df2.index\n","df2['ID_correto'] = index\n","df2 = df2.astype({\"ID_correto\": str}, errors='raise') \n","df2.to_excel(\"teste4.xlsx\", sheet_name='Sheet_name_1')"],"metadata":{"id":"LOAVVL441kUg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = df2.index\n","df2['ID_correto'] = index\n","df2 = df2.astype({\"ID_correto\": str}, errors='raise') \n","df2.to_excel(\"86-95Teste7.xlsx\", sheet_name='Sheet_name_1')"],"metadata":{"id":"JKK2S_N--MZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##dicionario = dic[0]\n","#word_to_check = 'Esperantina'\n","#ambiguas = ['Água Boa', 'Água Branca', 'Alagoinha', 'Alto Alegre', 'Alto Paraíso', 'Alvorada', 'Amparo', 'Anchieta', 'Antônio Carlos', 'Aparecida', 'Araguanã', 'Araruna', 'Areia Branca', 'Atalaia', 'Aurora', 'Bandeirantes', 'Baraúna', 'Barra Bonita', 'Barracão', 'Barro Alto', 'Batalha', 'Belém', 'Belmonte', 'Boa Esperança', 'Boa Vista', 'Bocaina', 'Bom Jardim', 'Bom Jesus', 'Bom Jesus do Tocantins', 'Bom Sucesso', 'Bonfim', 'Bonito', 'Borborema', 'Brejinho', 'Buritis', 'Cachoeira Dourada', 'Cachoeirinha', 'Cafelândia', 'Caiçara', 'Campestre', 'Campo Alegre', 'Campo Grande', 'Canápolis', 'Canarana', 'Candeias', 'Cantagalo', 'Capanema', 'Capela', 'Caracol', 'Caraúbas', 'Cascavel', 'Catanduvas', 'Cedral', 'Cedro', 'Centenário', 'Colinas', 'Colorado', 'Condado', 'Conde', 'Cruzeiro do Sul', 'Davinopólis', 'Douradinha', 'Eldorado', 'Entre Rios', 'Esperantina', 'Estrela do Norte', 'Fátima', 'Feira Nova', 'Filadélfia', 'Floresta', 'Formoso', 'General Carneiro', 'Gravataí', 'Guaíra', 'Guaraci', 'Guaraciaba', 'Hidrolândia', 'Humaitá', 'Iguatu', 'Inajá', 'Independência', 'Indianápolis', 'Ipueiras', 'Iracema', 'Irati', 'Itabaiana', 'Itajá', 'Itambé', 'Itapeva', 'Itapiranga', 'Itaporanga', 'Jaborandi', 'Jacutinga', 'Jandaíra', 'Japurá', 'Jardim', 'Jardinópolis', 'Jatobá', 'Jundiá', 'Jurema', 'Jussara', 'Lagoa Grande', 'Lagoa Santa', 'Lajeado', 'Laranjal', 'Maravilha', 'Massaranduba', 'Mesquita', 'Milagres', 'Mirador', 'Monte Alegre', 'Monte Castelo', 'Morrinhos', 'Mulungu', 'Mundo Novo', 'Natividade', 'Nazaré', 'Nova Aurora', 'Nova Fátima', 'Nova Olímpia', 'Nova Olinda', 'Nova Santa Rita', 'Nova União', 'Nova Veneza', 'Novo Horizonte', 'Novo Santo Antônio', 'Ouro Branco', 'Ouro Verde', 'Pacatuba', 'Palestina', 'Palmas', 'Palmeira', 'Palmital', 'Paraíso', 'Parnamirim', 'Passagem', 'Pau D’Arco', 'Paulista', 'Pedra Branca', 'Pedra Preta', 'Petrolândia', 'Pilar', 'Pilões', 'Pinhalzinho', 'Pinhão', 'Pitangueiras', 'Planaltina', 'Planalto', 'Praia Grande', 'Prata', 'Presidente Bernardes', 'Presidente Dutra', 'Presidente Juscelino', 'Presidente Kennedy', 'Presidente Médici', 'Primavera', 'Queimadas', 'Redenção', 'Riachão', 'Riachinho', 'Riacho de Santana', 'Riachuelo', 'Rio Branco', 'Rio Claro', 'Rio Negro', 'Rio Verde', 'Ruy Barbosa', 'Salgadinho', 'Saltinho', 'Santa Bárbara', 'Santa Cecília', 'Santa Cruz', 'Santa Filomena', 'Santa Helena', 'Santa Inês', 'Santa Isabel', 'Santa Lúcia', 'Santa Luzia', 'Santa Maria', 'Santa Rita', 'Santa Rosa de Lima', 'Santa Teresinha', 'Santa Terezinha', 'Santana', 'Santarém', 'Santo André', 'São Bento', 'São Carlos', 'São Domingos', 'São Francisco', 'São Francisco de Paula', 'São Gabriel', 'São Gonçalo do Amarante', 'São João', 'São João Batista', 'São João do Paraíso', 'São José do Divino', 'São Martinho', 'São Pedro', 'São Sebastião', 'São Simão', 'São Tomé', 'São Vicente', 'São Vicente Ferrer', 'Sapucaia', 'Sarandi', 'Serrinha', 'Sertãozinho', 'Sítio Novo', 'Sobradinho', 'Soledade', 'Tabatinga', 'Tangará', 'Tapejara', 'Tapira', 'Tapiraí', 'Tavares', 'Teodoro Sampaio', 'Terra Nova', 'Terra Roxa', 'Toledo', 'Trindade', 'Triunfo', 'Turmalina', 'Turvo', 'Valença', 'Vargem', 'Vargem Bonita', 'Várzea', 'Várzea Grande', 'Vera Cruz', 'Viana', 'Viçosa', 'Wenceslau Braz', 'São Paulo', 'Rio de Janeiro']\n","#a = process.extract(word_to_check,result,limit=3)\n","#res = str(fillVName(word_to_check))\n","#print(res)\n","#dif.get_close_matches(res, ambiguas, n=1, cutoff=0.7)\n","#print(resamb)"],"metadata":{"id":"grZvkjJIWYw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = str(fillVName('Vicosa MG')) \n","df3 = pd.DataFrame(columns=('ID', '%Similaridade', 'Local_Sugerido','Ambiguidade'))\n","dif.get_close_matches(res, ambiguas, n=1, cutoff=1)\n","if not dif.get_close_matches(res, ambiguas, n=1, cutoff=1):\n","    df3.loc[i] = ['0', str(fillVmatch(res)), res,'N']\n","else:\n","    df3.loc[i] = ['0', str(fillVmatch(res)), res,'S']\n","df3"],"metadata":{"id":"wLZ4rUcOKJx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["orig = 'viçosa mg'\n","orig2 = list(orig)\n","seq_matcher = dif.SequenceMatcher(None, orig2, res)\n","for operation, i1,i2,j1,j2 in seq_matcher.get_opcodes():\n","    if operation == \"delete\":\n","        print(\"Deleting Sequence : '{}' from l1\".format(orig[i1:i2]))\n","        orig2[i1:i2] = [\"\"] * len(orig[i1:i2])\n","    #elif operation == \"replace\":\n","     #   print(\"Replacing Sequence : '{}' in l1 with '{}' in l2\".format(orig[i1:i2], res[j1:j2]))\n","     #   orig2[i1:i2] = [\"\"] * len(orig[i1:i2])\n","     #   orig2.insert(i1, res[j1:j2])\n","    #elif operation == \"insert\":\n","     #   print(\"Inserting Sequence : '{}' from l2 at {} in l1\".format(res[j1:j2], i1))\n","      #  orig2.insert(i1, res[j1:j2])\n","    elif operation == \"equal\":\n","        print(\"Equal Sequences. '{}' No Action Needed.\".format(orig[i1:i2]))\n","\n","print(\"\\nFinal Sequence : {}\".format(\"\".join(orig2)))"],"metadata":{"id":"wZw2A7LYlcr9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Deleting Sequence : '{}' from l1\".format(orig[i1:i2]))"],"metadata":{"id":"yKbhyfN5rPVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dicionario = dic[0]\n","dicionario2 = {}\n","index = 0\n","limit = 50\n","#df2 = pd.DataFrame(columns=('ID', '%Similaridade', 'Local_Sugerido','Ambiguidade'))\n","for i in dicionario:\n","   index += 1\n","   if index == limit:\n","        break\n","   print(str(fillVName(re.sub('\\W+',' ', dicionario[i]))))\n","   print(str(fillVmatch(dicionario[i])))\n","   print(str(re.sub('\\W+',' ', dicionario[i])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWACBWEMa0De","executionInfo":{"status":"ok","timestamp":1659408225933,"user_tz":180,"elapsed":179254,"user":{"displayName":"Arthur Filipe Sousa Gomes","userId":"14928857500750418910"}},"outputId":"71dcbe5e-b490-4a13-e484-38c3e0d36086"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["recife\n","100\n","recife\n","icó\n","90\n","méxico\n","brasília\n","90\n","brasília df\n","\n","0\n","guadalajara jalisco \n","icó\n","90\n","ciudad de méxico\n","nova brasilândia d'oeste\n","90\n","brasil\n","são paulo\n","100\n","são paulo\n","icó\n","90\n","méxico\n","rio de janeiro\n","100\n","rio de janeiro\n","horizonte\n","90\n","belo horizonte minas gerais\n","0\n","0\n","\n","brasília\n","90\n","brasil brasília\n","\n","0\n","gama df brazil\n","teresina\n","95\n","teresina pi\n","açu\n","90\n","são paulo brasil\n","0\n","0\n","\n","barra do garças\n","95\n","barra do garças mt\n","uauá\n","90\n","alcaldía cuauhtemoc\n","nova brasilândia d'oeste\n","90\n","brasil\n","macaé\n","100\n","macaé\n","nova brasilândia d'oeste\n","90\n","brasil\n","0\n","0\n","\n","barra do garças\n","95\n","barra do garças mt\n","brasília\n","95\n","brasília df\n","brasília\n","90\n","brasília df\n","\n","0\n","entre vênus e marte aprox \n","0\n","0\n","\n","\n","0\n","a pale blue dot in space\n","são josé dos campos\n","95\n","são josé dos campos sp\n","nova brasilândia d'oeste\n","90\n","brasil\n","\n","0\n","dublin city ireland\n","nova brasilândia d'oeste\n","90\n","brasil\n","barra do garças\n","95\n","barra do garças mt\n","teresina\n","95\n","teresina pi\n","manaus\n","90\n","manaus brasilien\n","0\n","0\n","\n","0\n","0\n","\n","ceará\n","90\n","ceará brazil\n","florianópolis\n","90\n","florianópolis brasil\n","uraí\n","90\n","gs zz9 plural z α earth\n","apucarana\n","90\n","apucarana pr\n","brasiléia\n","90\n","brasilia brazil\n","rio de janeiro\n","90\n","rio de janeiro brasil\n","manaus\n","100\n","manaus\n","nova brasilândia d'oeste\n","90\n","brasil\n","apucarana\n","90\n","apucarana pr\n","0\n","0\n","\n","itaú\n","90\n","quitandinha brasil\n","brasília\n","90\n","brasília brasil\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1oQZeWv9uxFqv0nfxqZtcI6w85R0Kv0r_","timestamp":1659493102551},{"file_id":"1X70c6wbQB_-ytAFgMRO_SVLzMe4725R9","timestamp":1657245843826},{"file_id":"1DbNIFLEpb2mlvd-HUQc5SY7v7bEIqU8r","timestamp":1657244028032},{"file_id":"1GzrRDE4msOhfJB-IUHw0h_lqPUb1aAtn","timestamp":1657161323102}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}